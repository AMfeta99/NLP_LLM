# Natural Language processing & Large Language Models | NLP & LLM
This repository is dedicated to projects and some theoretical material that I used to get into the areas of NLP and LLM in a practical/efficient way.


## Master Thesis
My NLP journey started in 2021-2022 during the development of my master's thesis entitled:
### ["Learning to write medical reports from EEG data"](https://repositorio-aberto.up.pt/handle/10216/144617) 
This aims the development of methods for clinical report writing based on EEG signals, adapting current NLP techniques and state-of-the-art captioning approaches to image, signal and video. 

Due Legal/privacy restrictions, code/implementation cannot be publicly available, however the dissertation has been published and can be accessed at [link](https://repositorio-aberto.up.pt/handle/10216/144617). 

The document includes an introdutions to NLP, state-of-the-art approach for captioning in image/signal/video, details development and comparison of 6 pipelines for EEG captioning.


## Courses
Since then, interest and popularity in the area has been growing, particularly due to the emergence of transformers and LLM applications. So, in an attempt to keep up with this development, I took some courses on more recent topics in the areas offered by some of the big players. This repository includes some theoretical/notes and pratical material of thoses.
### [Generative AI with Large Language Models](https://www.deeplearning.ai/courses/generative-ai-with-llms/) (DeepLearning.AI & AWS)
  - Deeply understand generative AI, describing the key steps in a typical LLM-based generative AI lifecycle, from data gathering and model selection, to performance evaluation and deployment.
  - Describe in detail the transformer architecture that powers LLMs, how they’re trained, and how fine-tuning enables LLMs to be adapted to a variety of specific use cases.
  - Use empirical scaling laws to optimize the model's objective function across dataset size, compute budget, and inference requirements.
  - Apply state-of-the art training, tuning, inference, tools, and deployment methods to maximize the performance of models within the specific constraints of your project.
  - Challenges and opportunities that generative AI creates for businesses after hearing stories from industry researchers and practitioners.
#### Course Certificate: [Link](https://www.coursera.org/account/accomplishments/certificate/Y2C2XJL6JMPW); [More Info](https://www.coursera.org/account/accomplishments/verify/Y2C2XJL6JMPW)

## Relevant/Hot Topics
### Finetuning LLMs
### [Finetuning Large Language Models](https://www.coursera.org/programs/bosch-learning-program-8hold/projects/finetuning-large-language-models-project?source=search) (DeepLearning.AI & LAMINI)
  -  Essential finetuning concepts and how to train a large language model.
  -  Understand how finetuning differs from prompt engineering, and when to use both.
  -  Practical experience with real data sets, and how to use techniques for projects.
#### Course Certificate: [Link](https://learn.deeplearning.ai/accomplishments/0478e5ad-9140-472d-a957-9fcd441a2073?usp=sharing); [More Info](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)

### Large Language Model Operations
### [LLMOps](https://www.deeplearning.ai/short-courses/llmops/?utm_campaign=googlecloud3-launch&utm_medium=announcement&utm_source=discourse) (DeepLearning.AI & Google Cloud)
  - Retrieve and transform training data for supervised fine-tuning of an LLM.
  - Version data and tuned models to track your tuning experiments.
  - Configure an open-source supervised tuning pipeline and then execute that pipeline to train and then deploy a tuned LLM.
  - Output and study safety scores to responsibly monitor and filter your LLM application’s behavior.
  - Tun and deploy LLM
  - Practice with Tools as BigQuery data warehouse, the open-source Kubeflow Pipelines, and Google Cloud.
#### Course Certificate: [Link](https://learn.deeplearning.ai/accomplishments/10ca5b0b-28b4-42e2-a909-5b6e6a81c8d2?usp=sharing); [More Info](https://www.deeplearning.ai/short-courses/llmops/)

### Retrieval Augmented Generation (RAG)
### [LangChain Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/) (DeepLearning.AI & LangChain)
  - Retrieval Augmented Generation (RAG), a common LLM application that retrieves contextual documents from an external dataset.
  - Building a chatbot that responds to queries based on the content of your documents, rather than the information it has learned in training.
#### Course Certificate: [Link](); [More Info](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)


### Disclaimer
Copyright of all materials in thoses courses belongs to DeepLearning.AI, LAMINI, AWS and Google Cloud and can only be used or distributed for educational purpose. You may not use or distribute them for commercial purposes.

### Resources
https://www.deeplearning.ai/resources/natural-language-processing/?utm_campaign=Pillar%20pages&utm_content=286795896&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18246783

https://github.com/MalayAgr/generative-ai-with-llms-notes?tab=readme-ov-file

https://github.com/andysingal/LLMops/tree/main
