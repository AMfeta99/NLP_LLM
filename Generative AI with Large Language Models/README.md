# Generative AI With Large Language Models

The repository contains:
## Code Assignments:
 - Summarize_dialogue Lab (Week 1) - Dialogue summarization task using generative AI. Perform prompt engineering (compare zero shot, one shot, and few shot inferences).
 - Fine-Tuning Lab (Week 2) - Instruction Fine-Tuning using LoRA. Perform PEFT fine-tuning, evaluate the resulting model.
 - RLHF Lab (Week 3)- Reinforcement Learning From Human Feedback to align LLMs. Fine-tune FLAN-T5 with RL to generate more-positive summaries.

## Notes & Content
[Week 1](https://github.com/AMfeta99/NLP_LLM/blob/635d865411ae18c2edef290a73a6d07675c8b3ee/Generative%20AI%20with%20Large%20Language%20Models/w1/GenAI_LLM_1.pdf):
  - Generative AI & LLMs 
  - Transformers 
  - Prompting and Prompt Engineering 
  - Generative AI project lifecycle 
  - Pre-training Large Language Models 
  - Computational challenge in Training LLMs
  - Compute-Optimal Models
  - Domain Adaptation
  - Efficient Multi-GPU Compute Strategies

[Week 2](https://github.com/AMfeta99/NLP_LLM/blob/635d865411ae18c2edef290a73a6d07675c8b3ee/Generative%20AI%20with%20Large%20Language%20Models/w2/GenAI_LLM_2.pdf):
  - Limitations of ICL
  - Instruction Fine-Tuning 
  - Model Evaluation
  - Benchmarks 
  - Parameter Efficient Fine Tuning (PEFT)

Week 3:
  - Human/Model Alignment
  - Reinforcement Learning From Human Feedback (RLHF)
  - Model Self-Supervision with Constitutional AI
