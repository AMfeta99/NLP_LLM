# Generative AI With Large Language Models

The repository contains:
## Code Assignments:
 - Summarize_dialogue Lab (Week 1) - Dialogue summarization task using generative AI. Perform prompt engineering (compare zero shot, one shot, and few shot inferences).
 - Fine-Tuning Lab (Week 2) - Instruction Fine-Tuning using LoRA. Perform PEFT fine-tuning, evaluate the resulting model.
 - RLHF Lab (Week 3)- Reinforcement Learning From Human Feedback to align LLMs. Fine-tune FLAN-T5 with RL to generate more-positive summaries.

## Notes & Content
Week 1:
  - Generative AI & LLMs - Definition, concepts, terminology and use cases.
  - Transformers - Before transformers, key concepts, transformers architecture, types and configurations of transformers
  - Prompting and Prompt Engineering - Basics of prompting, prompt engineering and inference configuration parameters (temperature, etc).
  - Generative AI project lifecycle - 
  - Pre-training Large Language Models - Model selection, LLMs are pre-trained.
  - Computational challenge in Training LLMs
  - Compute-Optimal Models
  - Domain Adaptation
  - Efficient Multi-GPU Compute Strategies - Approaches available for training LLMs in a distributed manner.

Week 2:
  - Instruction Fine-Tuning - Basics of fine-tuning LLMs.
  - Model Evaluation - Metrics and Benchmarks - Details on evaluation metrics and benchmarks for LLMs.
  - Parameter Efficient Fine Tuning (PEFT) - Basics of PEFT, covering LoRA and Soft Prompts.

Week 3:
  - Reinforcement Learning From Human Feedback (RLHF) - Basics of RLHF.
